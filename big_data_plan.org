
* Question we're Answering
** How many questions are asked on IRC from:
*** #nodejs
*** #ruby
*** #rubyonrails

* Front End
** Program that listens onto freenode and records information from channels
*** Talks to an intermediary proxy which sends info off to cluster
** Multiplexed? One-way?

* Backend
** Spark/Scala
** AWS
** Kafka
   

* TODO Questions [3/10]
** DONE How do we setup Spark on a Mac?
- ensure Java is installed [[http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html][Install Java]]
- go to the Downloads page: http://spark.apache.org/downloads.html || brew install apache-spark
- choose the latest version
- choose "Pre-built for Hadoop 2.6 and later" as the package type
- use "select apache mirror"
- click the link below "select apache mirror" to go to the mirror page
- use the suggested mirror to download it
- run tar xzf <filename> to extract it
- cd into the directory and run bin/spark-shell
** TODO How to run spark in Python or Scala

pyspark     - python console
spark-shell - scala console

** TODO How do I setup Spark?
** DONE How is Spark setup on a Cluster/AWS?
Saturday - 04/02/2016 - 02:28 PM PDT There's a spark EC2 link

*** Launching on a Cluster
**** Description
The Spark cluster mode overview explains the key concepts in running on a cluster. Spark can run both by itself, or over several existing cluster managers. It currently provides several options for deployment:

Amazon EC2: our EC2 scripts let you launch a cluster in about 5 minutes
Standalone Deploy Mode: simplest way to deploy Spark on a private cluster
Apache Mesos
Hadoop YARN
Where

**** Resources/Links
[[http://spark.apache.org/docs/latest/cluster-overview.html][Cluster Overview]]
[[http://spark.apache.org/docs/latest/ec2-scripts.html][Spark EC2 Script]]
[[http://spark.apache.org/docs/latest/spark-standalone.html][Spark Standalone Mode]]
[[http://spark.apache.org/docs/latest/running-on-yarn.html][Running Spark on Yarn]]

** TODO How is Spark setup locally
** TODO How do we cluster spark?
** TODO How do we run spark map/reduce?
** TODO How do we run streaming operations through spark?

** TODO How do we stream information from IRC to Spark and map/reduce it?
** DONE What is Amazon EC2?
Amazon Elastic Compute Cloud (EC2) forms a central part of Amazon.com's cloud-computing platform, Amazon Web Services (AWS), by allowing users to rent virtual computers on which to run their own computer applications.


* Docker  
Docker containers wrap up a piece of software in a complete filesystem that contains everything it needs to run: code, runtime, system tools, system libraries – anything you can install on a server. This guarantees that it will always run the same, regardless of the environment it is running in.

* Amazon EC2 
** Resources
[[http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EC2_GetStarted.html][Getting Started]]


* Google Cloud Platform
  
* Kubernetes
Kubernetes is an open source container cluster manager. It schedules any number of container replicas across a group of node instances. A master instance exposes the Kubernetes API, through which tasks are defined. Kubernetes spawns containers on nodes to handle the defined tasks.

The number and type of containers can be dynamically modified according to need. An agent (a kubelet) on each node instance monitors containers and restarts them if necessary.

Kubernetes is optimized for Google Cloud Platform, but can run on any physical or virtual machine.

To get started, visit the Kubernetes home page.

* Google Cloud Guide
[[https://interactive-tutorial.appspot.com/][10 Minute Interactive Tutorial]]
[[https://cloud.google.com/sdk/gcloud/?_ga=1.259953353.231660072.1459633923][GCloud API]]
** Example 10 min tutorial
*** View your web server in a browser
**** gcloud compute instances list my-instance
***** Sample Ouput
  NAME	ZONE	MACHINE_TYPE	PREEMPTIBLE	INTERNAL_IP	EXTERNAL_IP	STATUS
  my-instance	us-central1-b	n1-standard-1		10.240.0.2	198.51.100.0	RUNNING



        

        



*** Store Files
 When you upload files to Google Cloud Storage, they are backed up to multiple physical locations. This ensures your files are protected even if a data center goes down and makes it possible for you—from anywhere in the world—to have fast access to them.

**** gsutil cp -r /sample-files gs://interactive-tutorial-xrq86s-bucket [/]
***** What does gsutil do?
***** Why do we pass cp to gsutil as an argument?
***** What does gs:// mean? Seems releated to a bucket.
***** Output

 cj3kim@my-instance:~$ gsutil cp -r /sample-files gs://interactive-tutorial-xrq86s-bucket

 Copying file:///sample-files/shakespeare.csv [Content-Type=text/csv]...
 Uploading   ...orial-xrq86s-bucket/sample-files/shakespeare.csv: 4.41 MiB/4.41 MiB      
 Copying file:///sample-files/sample.sql [Content-Type=application/x-sql]...

 Uploading   ...e-tutorial-xrq86s-bucket/sample-files/sample.sql: 7.63 KiB/7.63 KiB    
 Copying file:///sample-files/public/photo.jpg [Content-Type=image/jpeg]...
 Uploading   ...rial-xrq86s-bucket/sample-files/public/photo.jpg: 99.73 KiB/99.73 KiB    

 cj3kim@my-instance:~$ man gsutil
*** Make some files public
**** One Command
 gsutil acl ch -r -u AllUsers:READ \ gs://interactive-tutorial-xrq86s-bucket/sample-files/public

*** View public files
 Test that the file is public by clicking the following link and viewing the page in your browser. 
 http://storage.googleapis.com/interactive-tutorial-xrq86s-bucket/sample-files/public/phot
https://cloud.google.com/sdk/gcloud/?_ga=1.259953353.231660072.1459633923


* TODO Logistal Tasks [1/3]
** TODO Setup Amazon EC2 Account
** TODO Setup Spark locally 
** DONE Setup Slack 



* Links   
[[http://spark.apache.org/docs/latest/quick-start.html][Quick Start]]
[[http://spark.apache.org/docs/latest/programming-guide.html][Spark Programming Guide]]



* Slack Notes
[[https://slack.com/apps][App Market]]
