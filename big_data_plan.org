
* Question we're Answering
** How many questions are asked on IRC from:
*** #nodejs
*** #ruby
*** #rubyonrails

* Front End
** Program that listens onto freenode and records information from channels
*** Talks to an intermediary proxy which sends info off to cluster
** Multiplexed? One-way?

* Backend
** Spark/Scala
** AWS
** Kafka
   

* TODO Questions [7/10]
** TODO How do we cluster spark?
** TODO How do we run streaming operations through spark?

** TODO How do we stream information from IRC to Spark and map/reduce it?
** DONE How to run spark in Python or Scala

pyspark     - python console
spark-shell - scala console

** DONE How do we run spark map/reduce?
** DONE How do I setup Spark?
** DONE How is Spark setup locally
** DONE How do we setup Spark on a Mac?
- ensure Java is installed [[http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html][Install Java]]
- go to the Downloads page: http://spark.apache.org/downloads.html || brew install apache-spark
- choose the latest version
- choose "Pre-built for Hadoop 2.6 and later" as the package type
- use "select apache mirror"
- click the link below "select apache mirror" to go to the mirror page
- use the suggested mirror to download it
- run tar xzf <filename> to extract it
- cd into the directory and run bin/spark-shell
** DONE How is Spark setup on a Cluster/AWS?
Saturday - 04/02/2016 - 02:28 PM PDT There's a spark EC2 link

*** Launching on a Cluster
**** Description
The Spark cluster mode overview explains the key concepts in running on a cluster. Spark can run both by itself, or over several existing cluster managers. It currently provides several options for deployment:

Amazon EC2: our EC2 scripts let you launch a cluster in about 5 minutes
Standalone Deploy Mode: simplest way to deploy Spark on a private cluster
Apache Mesos
Hadoop YARN
Where

**** Resources/Links
[[http://spark.apache.org/docs/latest/cluster-overview.html][Cluster Overview]]
[[http://spark.apache.org/docs/latest/ec2-scripts.html][Spark EC2 Script]]
[[http://spark.apache.org/docs/latest/spark-standalone.html][Spark Standalone Mode]]
[[http://spark.apache.org/docs/latest/running-on-yarn.html][Running Spark on Yarn]]

** DONE What is Amazon EC2?
Amazon Elastic Compute Cloud (EC2) forms a central part of Amazon.com's cloud-computing platform, Amazon Web Services (AWS), by allowing users to rent virtual computers on which to run their own computer applications.


* Docker  
Docker containers wrap up a piece of software in a complete filesystem that contains everything it needs to run: code, runtime, system tools, system libraries – anything you can install on a server. This guarantees that it will always run the same, regardless of the environment it is running in.

* Amazon EC2 
** Resources
[[http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EC2_GetStarted.html][Getting Started]]

* Google Cloud Platform
* Kubernetes
Kubernetes is an open source container cluster manager. It schedules any number of container replicas across a group of node instances. A master instance exposes the Kubernetes API, through which tasks are defined. Kubernetes spawns containers on nodes to handle the defined tasks.

The number and type of containers can be dynamically modified according to need. An agent (a kubelet) on each node instance monitors containers and restarts them if necessary.

Kubernetes is optimized for Google Cloud Platform, but can run on any physical or virtual machine.

To get started, visit the Kubernetes home page.

** Kubernetes Spark Example
[[https://docs.docker.com/engine/installation/mac/][docker mac]]   
[[https://cloud.google.com/sdk/gcloud/reference/][gcloud reference]] 
[[https://cloud.google.com/sdk/gcloud/][gcloud tool guide]]  
[[http://blog.arungupta.me/key-concepts-kubernetes/][kubernetes concepts]]



*** Commands
**** gcloud container clusters get-credentials spark
**** kubectl logs spark-master-controller-lg8u3
16/04/03 01:31:53 INFO Master: Registered signal handlers for [TERM, HUP, INT]
16/04/03 01:31:53 INFO SecurityManager: Changing view acls to: root
16/04/03 01:31:53 INFO SecurityManager: Changing modify acls to: root
16/04/03 01:31:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/04/03 01:31:54 INFO Slf4jLogger: Slf4jLogger started
16/04/03 01:31:54 INFO Remoting: Starting remoting
16/04/03 01:31:54 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkMaster@spark-master:7077]
16/04/03 01:31:55 INFO Utils: Successfully started service 'sparkMaster' on port 7077.
16/04/03 01:31:55 INFO Master: Starting Spark master at spark://spark-master:7077
16/04/03 01:31:55 INFO Master: Running Spark version 1.5.2
16/04/03 01:31:55 INFO Utils: Successfully started service 'MasterUI' on port 8080.
16/04/03 01:31:55 INFO MasterWebUI: Started MasterWebUI at http://10.0.1.4:8080
16/04/03 01:31:55 INFO Utils: Successfully started service on port 6066.
16/04/03 01:31:55 INFO StandaloneRestServer: Started REST server for submitting applications on port 6066
16/04/03 01:31:55 INFO Master: I have been elected leader! New state: ALIVE

**** kubectl exec zeppelin-controller-3yr67 --it pyspark

*** Step 1
    
**** Prereqs
     
     1. Have a kubernetes cluster installed and running
     2. Have the kubectl command line tool installed
     3. That a spark-master service which spins up will be automatically discoverable by your kube DNS impl, as 'spark-master'


     


* Google Cloud Guide
[[https://interactive-tutorial.appspot.com/][10 Minute Interactive Tutorial]]
[[https://cloud.google.com/sdk/gcloud/?_ga=1.259953353.231660072.1459633923][GCloud API]]
** Example 10 min tutorial
*** View your web server in a browser
**** gcloud compute instances list my-instance
***** Sample Ouput
  NAME	ZONE	MACHINE_TYPE	PREEMPTIBLE	INTERNAL_IP	EXTERNAL_IP	STATUS
  my-instance	us-central1-b	n1-standard-1		10.240.0.2	198.51.100.0	RUNNING



        

        



*** Store Files
 When you upload files to Google Cloud Storage, they are backed up to multiple physical locations. This ensures your files are protected even if a data center goes down and makes it possible for you—from anywhere in the world—to have fast access to them.

**** gsutil cp -r /sample-files gs://interactive-tutorial-xrq86s-bucket [/]
***** What does gsutil do?
***** Why do we pass cp to gsutil as an argument?
***** What does gs:// mean? Seems releated to a bucket.
***** Output

 cj3kim@my-instance:~$ gsutil cp -r /sample-files gs://interactive-tutorial-xrq86s-bucket

 Copying file:///sample-files/shakespeare.csv [Content-Type=text/csv]...
 Uploading   ...orial-xrq86s-bucket/sample-files/shakespeare.csv: 4.41 MiB/4.41 MiB      
 Copying file:///sample-files/sample.sql [Content-Type=application/x-sql]...

 Uploading   ...e-tutorial-xrq86s-bucket/sample-files/sample.sql: 7.63 KiB/7.63 KiB    
 Copying file:///sample-files/public/photo.jpg [Content-Type=image/jpeg]...
 Uploading   ...rial-xrq86s-bucket/sample-files/public/photo.jpg: 99.73 KiB/99.73 KiB    

 cj3kim@my-instance:~$ man gsutil
*** Make some files public
**** One Command
 gsutil acl ch -r -u AllUsers:READ \ gs://interactive-tutorial-xrq86s-bucket/sample-files/public

*** View public files
 Test that the file is public by clicking the following link and viewing the page in your browser. 
 http://storage.googleapis.com/interactive-tutorial-xrq86s-bucket/sample-files/public/phot
https://cloud.google.com/sdk/gcloud/?_ga=1.259953353.231660072.1459633923

* TODO Logistal Tasks [1/3]
** TODO Setup Amazon EC2 Account
** TODO Setup Spark locally 
** DONE Setup Slack 



* Links   
[[http://spark.apache.org/docs/latest/quick-start.html][Quick Start]]
[[http://spark.apache.org/docs/latest/programming-guide.html][Spark Programming Guide]]
[[https://thinkbiganalytics.com/leading_big_data_technologies/ingestion-and-streaming-with-storm-kafka-flume/][nice-comparisons]]
* Slack Notes
[[https://slack.com/apps][App Market]]

* Things we need to study tonight [1/9]
** DONE Docker
[[https://docs.docker.com/engine/userguide/][docker user guide]]
[[https://docs.docker.com/engine/userguide/containers/dockerimages/][docker images]]
[[https://nodejs.org/en/docs/guides/nodejs-docker-webapp/][docking nodejs]]

** TODO Kubernetes
** TODO Spark 
** TODO gcloud
** TODO gsutil
** TODO the scheme: gs://
** TODO dataproc
** TODO How does gcloud holistically work with all the other tooling and interfaces?
** TODO How to SSH into a project

   
